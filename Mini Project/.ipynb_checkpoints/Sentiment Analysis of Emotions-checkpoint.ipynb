{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29cd0453-a44c-4ede-a628-ebaba1d58146",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Emotions\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The aim of this project is to classify emotions from text data using four machine learning models: Naive Bayes, Logistic Regression, Random Forest, and Support Vector Machine (SVM). Sentiment analysis, in the context of emotion classification, involves categorizing text based on the emotional tone it conveys. This has wide applications in customer service, social media monitoring, and emotional intelligence systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6632d98-5ec4-4aa6-b026-918097e863b0",
   "metadata": {},
   "source": [
    "#### Models Overview\n",
    "\n",
    "* Naive Bayes: A probabilistic classifier based on Bayes' Theorem, Naive Bayes assumes that the features (words) in the data are independent given the class (emotion). It is efficient and performs well with high-dimensional data like text, making it an excellent choice for text classification tasks, especially when the data is noisy.\n",
    "\n",
    "* Logistic Regression: This is a linear model for binary and multi-class classification problems. Logistic regression models the probability that a given input belongs to a particular class. It is a well-known and simple algorithm often used in text classification problems, particularly when the relationships between features and the target variable are assumed to be linear.\n",
    "\n",
    "* Random Forest: An ensemble learning method that constructs multiple decision trees and merges them to get a more accurate and stable prediction. It works well for complex datasets and is less prone to overfitting compared to a single decision tree. Random Forest is known for handling a large number of features, making it suitable for text data with many dimensions.\n",
    "\n",
    "* Support Vector Machine (SVM): A powerful classifier that works by finding the optimal hyperplane that separates the classes in high-dimensional space. SVM can efficiently handle both linear and non-linear data through kernel tricks, making it ideal for text data where class separation is complex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1818d2-a2c6-42fc-be8c-b06e2257b8f2",
   "metadata": {},
   "source": [
    "#### Evaluation Metrics\n",
    "In this project, we evaluate and compare the performance of the models using the following metrics:\n",
    "* Accuracy: The percentage of correctly classified instances out of all instances.\n",
    "\n",
    "* Precision: The ratio of correctly predicted positive instances to the total predicted positive instances, which indicates how reliable the modelâ€™s positive predictions are.\n",
    "\n",
    "* Recall (Sensitivity): The ratio of correctly predicted positive instances to all actual positive instances, indicating how well the model identifies positive instances.\n",
    "\n",
    "* F1 Score: The harmonic mean of precision and recall, providing a single metric to evaluate the balance between them.\n",
    "\n",
    "* Confusion Matrix: A matrix that shows the true vs. predicted classifications for each emotion label, offering insight into model performance for each class.\n",
    "\n",
    "We will evaluate these models on emotion-labeled datasets and compare their performance based on these metrics to identify the best-performing model for emotion classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca55cc2-b2c3-4de2-a502-532989a705fe",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries and Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5979a7e9-8630-4eeb-9a59-f3dd408483a2",
   "metadata": {},
   "source": [
    "#### 1.1 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07da468-21a0-46fc-9c1c-453fdc4a33d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Libraries for NLP and model building\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acd15dc-5978-4e8d-bbf9-e01b4955a865",
   "metadata": {},
   "source": [
    "#### 1.2 Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80bb120-f330-42d9-ad8f-03b68976b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test.txt dataset\n",
    "df = pd.read_csv('./dataset/train.txt', names=['Text', 'Emotion'], sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4b8d61-65ce-42b4-9831-48e12b934a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9481f47b-a55d-4edd-862b-ed1b94e5a753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the dataset (number of rows and columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad8a10-1714-43fe-bb23-3f9bc0210c48",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4bdce-8338-4f58-8421-da6991b745dd",
   "metadata": {},
   "source": [
    "#### 2.1 Cleaning the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1178be-f1f5-479d-bc11-154a32c00f0d",
   "metadata": {},
   "source": [
    "Remove the HTML tags, URL patters, unwanted patters, special characters and numbers, and removal of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41356a82-bf46-4757-be11-e2ca974c11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the text\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags using BeautifulSoup (in case some tags are still in text form)\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "    # Remove any URL patterns (http, https, ftp, etc.)\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    \n",
    "    # Remove any other unwanted patterns like href, src, etc.\n",
    "    text = re.sub(r'\\b(?:href|src|alt|title|class|id|style|rel|data)\\b', '', text)\n",
    "\n",
    "    # Remove special characters and numbers (keeping only alphabets and spaces)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove stopwords (optional, can be added if you have a stopwords list)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'Text' column\n",
    "df['Cleaned_Text'] = df['Text'].apply(clean_text)\n",
    "# Save the cleaned DataFrame to a CSV file\n",
    "df.to_csv('./dataset/cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85caad0-2f46-4e66-826f-078b23b8e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned text\n",
    "df[['Text', 'Cleaned_Text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726349a3-5a7d-40f7-bb7d-2eea9b09edcd",
   "metadata": {},
   "source": [
    "#### 2.2 Emotion Distribution using Pie Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4dc90e-6a91-4209-947b-f2a0e3eb28c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a pie chart of emotion counts\n",
    "emotion_counts = df['Emotion'].value_counts()\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(emotion_counts, labels=emotion_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette(\"Set3\", len(emotion_counts)))\n",
    "plt.title('Emotion Distribution in Dataset')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie chart is circular.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f981e33-cb66-4cb2-8ac2-ebb00083061f",
   "metadata": {},
   "source": [
    "#### 2.3 Emotion Counts using Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5a384-6e0b-4f3f-8d28-502e6c4a2b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display emotion counts\n",
    "emotion_counts = df['Emotion'].value_counts()\n",
    "\n",
    "# Convert the emotion counts to a DataFrame for use in seaborn\n",
    "emotion_counts_df = emotion_counts.reset_index()\n",
    "emotion_counts_df.columns = ['Emotion', 'Count']\n",
    "\n",
    "# Bar chart with hue assigned\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Emotion', y='Count', data=emotion_counts_df, palette=\"Set3\", hue='Emotion')\n",
    "plt.title('Emotion Count Distribution')\n",
    "plt.xlabel('Emotion')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad7112-c59f-4721-bf2b-58651157f1ea",
   "metadata": {},
   "source": [
    "#### 2.4 Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d8188-6d37-4d40-9048-f74061db05e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word clouds for each emotion category\n",
    "unique_emotions = df['Emotion'].unique()\n",
    "\n",
    "# Dynamically calculate the number of rows and columns for the subplots\n",
    "num_emotions = len(unique_emotions)\n",
    "cols = 2  # Fixed number of columns (you can adjust this)\n",
    "rows = np.ceil(num_emotions / cols).astype(int)  # Calculate the required rows\n",
    "\n",
    "# Create a plot for each emotion category\n",
    "plt.figure(figsize=(10, 5 * rows))\n",
    "for i, emotion in enumerate(unique_emotions, 1):\n",
    "    # Filter the DataFrame for the current emotion\n",
    "    emotion_text = df[df['Emotion'] == emotion]['Cleaned_Text'].str.cat(sep=' ')\n",
    "\n",
    "    # Generate the word cloud\n",
    "    wordcloud = WordCloud(width=500, height=500, background_color='white', max_words=200).generate(emotion_text)\n",
    "\n",
    "    # Display the word cloud\n",
    "    plt.subplot(rows, cols, i)  # Dynamically adjust subplots based on the number of categories\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Word Cloud for {emotion}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f0cbfa-b31b-4d8a-94e5-ec470420c717",
   "metadata": {},
   "source": [
    "#### 2.5 Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07da3c-aa4e-4039-9a34-153c42f4e6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical emotions to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df['Emotion_Label'] = label_encoder.fit_transform(df['Emotion'])\n",
    "\n",
    "# Display the mapping of labels\n",
    "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7415b596-6cb2-46dd-b13e-f887a3b0b816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Cleaned_Text', 'Emotion', 'Emotion_Label']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e34fb38-c097-4433-94fe-b10f2261a690",
   "metadata": {},
   "source": [
    "### 3. Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec6af13-d1a7-4285-a44e-13164697e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['Cleaned_Text'], df['Emotion_Label'], test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaea1c2-0b4b-40f7-8208-948bbfbd4c60",
   "metadata": {},
   "source": [
    "#### 3.1 TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c6ac7-1dcc-43f0-9d4e-af3f89ea1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidfvectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidfvectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d7ef2-bc55-4bee-b71d-83bed57f015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shape of the transformed features\n",
    "print(\"Shape of X_train:\", X_train_tfidf.shape)\n",
    "print(\"Shape of X_test:\", X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1235092-0964-40fe-8890-bdb953483e1a",
   "metadata": {},
   "source": [
    "### 4. Machine Learning Algorithms and Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff2013-d21e-4a31-8f6f-75150758b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define emotion labels mapping\n",
    "emotion_labels = {0: 'anger', 1: 'fear', 2: 'joy', 3: 'love', 4: 'sadness', 5: 'surprise'}\n",
    "\n",
    "# Define classifiers\n",
    "classifier = {\n",
    "    'MultinomialNB': MultinomialNB(),\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Support Vector Machine': SVC(),\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store results for plotting\n",
    "accuracy_results = {}\n",
    "\n",
    "# Set up the plot for accuracy bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "for name, clf in classifier.items():\n",
    "    # Fit the classifier\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Predict using the model\n",
    "    y_pred_tfidf = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "    accuracy_results[name] = accuracy_tfidf  # Store the accuracy\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"\\n============{name}============\")\n",
    "    print(f\"Accuracy: {accuracy_tfidf}\")\n",
    "    print(\"Classification Report\")\n",
    "    print(classification_report(y_test, y_pred_tfidf, target_names=[emotion_labels[i] for i in range(6)], zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc7911e-0556-4566-9041-8cd08a1b89cf",
   "metadata": {},
   "source": [
    "#### 4.2 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a1996f-336c-4859-8d04-cc333086ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart for accuracy results\n",
    "plt.bar(accuracy_results.keys(), accuracy_results.values(), color='skyblue')\n",
    "plt.title('Accuracy of Classifiers')\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608df32a-7439-41d1-a999-3eece36907a5",
   "metadata": {},
   "source": [
    "#### 4.3 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8857ebff-6524-48a3-90cd-b813857afbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot for confusion matrix heatmaps\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "for i, (name, clf) in enumerate(classifier.items()):\n",
    "    # Predict using the model\n",
    "    y_pred_tfidf = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_tfidf)\n",
    "    \n",
    "    # Plot confusion matrix as a heatmap\n",
    "    ax = axes[i//2, i%2]\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax,\n",
    "                xticklabels=[emotion_labels[i] for i in range(6)], \n",
    "                yticklabels=[emotion_labels[i] for i in range(6)])\n",
    "    ax.set_title(f'Confusion Matrix for {name}')\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "\n",
    "# Adjust layout for confusion matrix subplots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
