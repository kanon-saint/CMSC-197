{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a847b165-a231-4f11-bffd-c72d9b993d88",
   "metadata": {},
   "source": [
    "### Importing necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b6b9995-5ec5-4734-b0bc-a1c4962beb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import re\n",
    "import email\n",
    "import codecs\n",
    "from unidecode import unidecode\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23866527-ff74-451b-bdea-c4e4a9a3454e",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "28e4799c-0ae1-40a7-8727-537bbab51354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import codecs\n",
    "from unidecode import unidecode\n",
    "\n",
    "# Load stop words as a lowercase set\n",
    "with open('stop_words.txt', 'r') as file:\n",
    "    stop_words = {word.strip().lower() for word in file.readlines()}\n",
    "\n",
    "# Define punctuation, numbers, and escape characters to remove\n",
    "punc = r\"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\\\\\"\n",
    "num = \"0123456789\"\n",
    "esc = re.compile(r'\\\\[a-z][a-z]?[0-9]+')\n",
    "tags = re.compile('<.*?>')\n",
    "\n",
    "# Function to clean email message\n",
    "def removeWords(msg):\n",
    "    # Decode and normalize to remove encoding issues\n",
    "    msg = unidecode(codecs.decode(msg.encode('latin1', errors='ignore'), 'utf-8', errors='ignore')).lower()\n",
    "    \n",
    "    # Replace newlines and tabs with spaces and remove HTML tags\n",
    "    msg = msg.replace('\\n', ' ').replace('\\\\n', ' ').replace('\\r', ' ').replace('\\t', ' ').replace('\\\\t', ' ')..replace('\\\\\\t', ' ')\n",
    "    msg = re.sub(tags, '', msg)  # Remove HTML tags\n",
    "    msg = msg.translate(str.maketrans('', '', punc))  # Remove punctuation\n",
    "    msg = msg.translate(str.maketrans('', '', num))  # Remove numbers\n",
    "    msg = re.sub(esc, '', repr(msg))  # Remove escape characters\n",
    "    \n",
    "    words = msg.split()  # Split into words\n",
    "\n",
    "    # Remove stop words, stripping leading/trailing punctuation\n",
    "    filtered_words = [word.strip(\"'\") for word in words if word.strip(\"'\") not in stop_words]\n",
    "\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "678ee7e7-b6f3-4548-b7af-b1602dc1cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the email message from a parsed email\n",
    "def getMessage(parsed):\n",
    "    msg = \"\"\n",
    "    if parsed.is_multipart():  # Check if the email is multipart\n",
    "        for part in parsed.walk():  # Iterate through email parts\n",
    "            if part.get_content_type() == 'text/plain':  # Check for plain text\n",
    "                msg = part.get_payload()  # Get the message\n",
    "                break\n",
    "    else:\n",
    "        msg = parsed.get_payload()\n",
    "    return msg\n",
    "\n",
    "# Function to read labels file and store in a DataFrame\n",
    "def read_labels_to_dataframe(file_name):\n",
    "    data = []\n",
    "    with open(file_name, 'r') as f:\n",
    "        for line in f:\n",
    "            label, path = line.strip().split(' ', 1)  # Split label and path\n",
    "            cleaned_path = os.path.abspath(path.replace('../', ''))  # Clean the path\n",
    "            folder_number = os.path.basename(os.path.dirname(cleaned_path))  # Extract folder number\n",
    "            file_name_only = os.path.basename(cleaned_path)  # Extract file name\n",
    "            data.append((folder_number, file_name_only, cleaned_path, label))  # Store as a tuple\n",
    "    \n",
    "    # Create a DataFrame from the list of tuples\n",
    "    df = pd.DataFrame(data, columns=['Folder', 'File', 'Path', 'Label'])\n",
    "    return df\n",
    "\n",
    "# Function to read email content and clean it\n",
    "def read_email_content(df):\n",
    "    email_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        with open(row['Path'], 'r', encoding='ISO-8859-1') as email_file:\n",
    "            read_email_file = email_file.read()  # Read the email content\n",
    "            parsed = email.message_from_string(read_email_file)  # Parse the email\n",
    "            msg = getMessage(parsed)  # Get the message content\n",
    "            msg = removeWords(msg)  # Clean the message\n",
    "            email_data.append(msg)  # Store cleaned message\n",
    "\n",
    "    df['Content'] = email_data  # Add email content to the DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "532c6e8f-2426-48df-9e09-7cfb0939b255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folder</th>\n",
       "      <th>File</th>\n",
       "      <th>Content</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000</td>\n",
       "      <td>000</td>\n",
       "      <td>mailing list queried weeks ago running set arc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000</td>\n",
       "      <td>001</td>\n",
       "      <td>luxury watches buy rolex rolex cartier bvlgar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000</td>\n",
       "      <td>002</td>\n",
       "      <td>academic qualifications prestigious nonacc red...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000</td>\n",
       "      <td>003</td>\n",
       "      <td>greetings verify subscription planfans list ch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000</td>\n",
       "      <td>004</td>\n",
       "      <td>chauncey conferred luscious continued tonsilli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Folder File                                            Content  Label\n",
       "0    000  000  mailing list queried weeks ago running set arc...      0\n",
       "1    000  001   luxury watches buy rolex rolex cartier bvlgar...      1\n",
       "2    000  002  academic qualifications prestigious nonacc red...      1\n",
       "3    000  003  greetings verify subscription planfans list ch...      0\n",
       "4    000  004  chauncey conferred luscious continued tonsilli...      1"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Usage\n",
    "labels_file_name = 'labels'  # Update with your actual file name (no extension)\n",
    "df_labels = read_labels_to_dataframe(labels_file_name)\n",
    "df_labels = read_email_content(df_labels)\n",
    "\n",
    "# Remove the 'Path' column and adjust columns order\n",
    "df_labels = df_labels[['Folder', 'File', 'Content', 'Label']]\n",
    "\n",
    "# Change labels: ham -> 0, spam -> 1\n",
    "df_labels['Label'] = df_labels['Label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "34e9b85f-8df5-40e3-b611-166561d5b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "output_file_name = 'cleaned_emails.csv'  # Specify the output file name\n",
    "df_labels.to_csv(output_file_name, index=False)  # Save DataFrame without the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "67a297f4-3222-42bb-bf94-6642ffa7d8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Ham samples: 7523\n",
      "Training Spam samples: 13777\n",
      "Test samples: 16522\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned emails DataFrame from CSV\n",
    "df2 = pd.read_csv(\"cleaned_emails.csv\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "traindf = df2[df2['Folder'] < 71]  # Folders 0-70: Train Set\n",
    "testdf = df2[df2['Folder'] >= 71]  # Folders 71-127: Test Set\n",
    "\n",
    "# Separate training data into ham and spam\n",
    "trainingHam = traindf[traindf['Label'] == 0]  # Ham: Label 0\n",
    "trainingSpam = traindf[traindf['Label'] == 1]  # Spam: Label 1\n",
    "\n",
    "# Optional: Print the sizes of the resulting DataFrames\n",
    "print(\"Training Ham samples:\", trainingHam.shape[0])\n",
    "print(\"Training Spam samples:\", trainingSpam.shape[0])\n",
    "print(\"Test samples:\", testdf.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a1940e0d-dfb9-4727-a425-b88b79c1534f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'will': 11301,\n",
       " 'bbbb': 6711,\n",
       " 'board': 5145,\n",
       " 'company': 4533,\n",
       " 'price': 4496,\n",
       " 'gold': 4252,\n",
       " 'adobe': 4081,\n",
       " 'email': 4015,\n",
       " 'list': 3851,\n",
       " 'time': 3798,\n",
       " 'help': 3785,\n",
       " 'send': 3622,\n",
       " 'nil': 3604,\n",
       " 'message': 3596,\n",
       " 'dont': 3558,\n",
       " 'subject': 3474,\n",
       " 'crustl': 3268,\n",
       " 'received': 3090,\n",
       " 'program': 3076,\n",
       " 'windows': 2933,\n",
       " 'professional': 2782,\n",
       " 'work': 2765,\n",
       " 'wrote': 2680,\n",
       " 'well': 2639,\n",
       " 'ms': 2597,\n",
       " 'china': 2484,\n",
       " 'good': 2473,\n",
       " 'number': 2455,\n",
       " 'university': 2411,\n",
       " '\\\\t': 2386,\n",
       " 'problem': 2352,\n",
       " 'office': 2268,\n",
       " 'stock': 2243,\n",
       " 'file': 2235,\n",
       " 'microsoft': 2228,\n",
       " 'handyboard': 2202,\n",
       " 'hb': 2184,\n",
       " 'bit': 2182,\n",
       " 'de': 2170,\n",
       " 'corp': 2139,\n",
       " 'info': 2125,\n",
       " 'current': 2078,\n",
       " 'add': 2056,\n",
       " 'pro': 2000,\n",
       " 'studies': 1991,\n",
       " 'contenttype': 1973,\n",
       " 'news': 1972,\n",
       " 'nbsp': 1959,\n",
       " 'code': 1931,\n",
       " 'development': 1928,\n",
       " 'find': 1914,\n",
       " 'womens': 1880,\n",
       " 'great': 1848,\n",
       " 'people': 1835,\n",
       " 'today': 1802,\n",
       " 'best': 1787,\n",
       " 'read': 1780,\n",
       " 'system': 1761,\n",
       " 'save': 1756,\n",
       " 'power': 1739,\n",
       " 'motor': 1733,\n",
       " 'ic': 1724,\n",
       " 'call': 1723,\n",
       " 'text': 1646,\n",
       " 'days': 1630,\n",
       " 'handy': 1624,\n",
       " 'data': 1619,\n",
       " 'unsubscribe': 1614,\n",
       " 'address': 1603,\n",
       " 'fax': 1595,\n",
       " 'market': 1590,\n",
       " 'ive': 1586,\n",
       " 'mail': 1584,\n",
       " 'site': 1554,\n",
       " 'set': 1549,\n",
       " 'free': 1532,\n",
       " 'textplain': 1514,\n",
       " 'better': 1480,\n",
       " 'life': 1463,\n",
       " 'additional': 1449,\n",
       " 'xp': 1447,\n",
       " 'oil': 1445,\n",
       " 'day': 1439,\n",
       " 'offer': 1436,\n",
       " 'reviews': 1436,\n",
       " 'web': 1426,\n",
       " 'big': 1425,\n",
       " 'software': 1416,\n",
       " 'port': 1408,\n",
       " 'years': 1403,\n",
       " 'money': 1393,\n",
       " 'control': 1375,\n",
       " 'majordomovimsedu': 1373,\n",
       " 'computer': 1365,\n",
       " 'retail': 1364,\n",
       " 'campaign': 1356,\n",
       " 'website': 1350,\n",
       " 'rating': 1350,\n",
       " 'gas': 1345,\n",
       " '\\\\tby': 1320,\n",
       " 'week': 1319,\n",
       " 'forward': 1319,\n",
       " 'cart': 1304,\n",
       " 'contenttransferencoding': 1299,\n",
       " 'robot': 1284,\n",
       " 'technology': 1269,\n",
       " 'potential': 1260,\n",
       " 'experience': 1255,\n",
       " 'order': 1238,\n",
       " 'service': 1236,\n",
       " 'version': 1232,\n",
       " 'ra': 1229,\n",
       " 'energy': 1218,\n",
       " 'messages': 1210,\n",
       " 'based': 1196,\n",
       " 'project': 1195,\n",
       " 'exploration': 1191,\n",
       " 'going': 1178,\n",
       " 'mimeversion': 1177,\n",
       " 'real': 1169,\n",
       " 'problems': 1165,\n",
       " 'body': 1163,\n",
       " 'cantex': 1162,\n",
       " 'special': 1159,\n",
       " 'long': 1156,\n",
       " 'things': 1155,\n",
       " 'full': 1149,\n",
       " 'provide': 1142,\n",
       " 'motors': 1142,\n",
       " 'pm': 1136,\n",
       " 'post': 1117,\n",
       " 'high': 1117,\n",
       " 'question': 1112,\n",
       " 'business': 1110,\n",
       " 'report': 1108,\n",
       " 'thing': 1102,\n",
       " 'start': 1101,\n",
       " 'thu': 1100,\n",
       " 'sender': 1096,\n",
       " 'unicode': 1095,\n",
       " 'international': 1094,\n",
       " 'doesnt': 1084,\n",
       " 'works': 1082,\n",
       " 'replyto': 1081,\n",
       " 'small': 1072,\n",
       " 'httphyakushowcomtada': 1072,\n",
       " 'files': 1064,\n",
       " 'support': 1054,\n",
       " 'working': 1039,\n",
       " 'digital': 1036,\n",
       " 'serial': 1033,\n",
       " 'yew': 1030,\n",
       " 'check': 1027,\n",
       " 'account': 1019,\n",
       " 'sep': 1019,\n",
       " 'department': 1018,\n",
       " 'cant': 1016,\n",
       " 'expansion': 1015,\n",
       " 'download': 1015,\n",
       " 'contact': 1009,\n",
       " 'currently': 1003,\n",
       " 'space': 1002,\n",
       " 'original': 999,\n",
       " 'online': 997,\n",
       " '\\\\tfor': 994,\n",
       " 'science': 991,\n",
       " 'interested': 987,\n",
       " 'aug': 987,\n",
       " 'video': 985,\n",
       " 'plan': 983,\n",
       " 'jul': 979,\n",
       " 'investors': 978,\n",
       " 'mon': 974,\n",
       " 'receive': 967,\n",
       " 'txtadd': 965,\n",
       " 'change': 964,\n",
       " 'tue': 963,\n",
       " 'charsetusascii': 961,\n",
       " 'point': 960,\n",
       " 'second': 959,\n",
       " 'design': 957,\n",
       " 'infinex': 956,\n",
       " 'running': 939,\n",
       " 'apple': 935,\n",
       " 'dragon': 926,\n",
       " 'short': 922,\n",
       " 'year': 921,\n",
       " 'place': 920,\n",
       " 'error': 919,\n",
       " 'dear': 918,\n",
       " 'approved': 917,\n",
       " 'output': 913,\n",
       " 'technologies': 908,\n",
       " 'side': 906,\n",
       " 'effects': 905,\n",
       " 'claims': 904,\n",
       " 'properties': 903,\n",
       " 'messageid': 902,\n",
       " 'fri': 902,\n",
       " 'golden': 893,\n",
       " 'low': 892,\n",
       " 'input': 886,\n",
       " 'commands': 878,\n",
       " 'students': 874,\n",
       " 'fred': 871,\n",
       " 'access': 870,\n",
       " 'light': 863,\n",
       " 'release': 859,\n",
       " 'sensor': 859,\n",
       " 'companys': 853,\n",
       " 'services': 852,\n",
       " 'group': 847,\n",
       " 'cs': 843,\n",
       " 'esmtp': 839,\n",
       " 'including': 837,\n",
       " 'battery': 836,\n",
       " 'hope': 832,\n",
       " 'questions': 831,\n",
       " 'course': 831,\n",
       " 'hello': 829,\n",
       " 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa': 829,\n",
       " 'programs': 826,\n",
       " 'three': 819,\n",
       " 'systems': 818,\n",
       " 'note': 818,\n",
       " 'product': 815,\n",
       " 'fine': 814,\n",
       " 'internet': 811,\n",
       " 'fast': 810,\n",
       " 'st': 809,\n",
       " 'test': 806,\n",
       " 'application': 806,\n",
       " 'plain': 801,\n",
       " 'watch': 799,\n",
       " 'ir': 796,\n",
       " 'phone': 792,\n",
       " 'turn': 789,\n",
       " 'form': 789,\n",
       " 'kind': 788,\n",
       " 'pleased': 787,\n",
       " 'format': 784,\n",
       " 'crustlvimsedu': 784,\n",
       " 'future': 782,\n",
       " 'include': 781,\n",
       " 'limited': 780,\n",
       " 'idea': 777,\n",
       " 'servo': 777,\n",
       " 'standard': 776,\n",
       " 'cgdc': 776,\n",
       " 'pdt': 772,\n",
       " 'hours': 771,\n",
       " 'apr': 769,\n",
       " 'case': 769,\n",
       " 'common': 767,\n",
       " 'corporation': 765,\n",
       " 'chip': 764,\n",
       " 'memory': 763,\n",
       " 'pin': 763,\n",
       " 'pc': 760,\n",
       " 'pine': 755,\n",
       " 'mode': 754,\n",
       " 'women': 750,\n",
       " 'opportunities': 745,\n",
       " 'starting': 744,\n",
       " 'sonar': 744,\n",
       " 'prices': 739,\n",
       " 'statements': 737,\n",
       " 'class': 732,\n",
       " 'share': 730,\n",
       " 'write': 729,\n",
       " 'voltage': 729,\n",
       " 'edt': 728,\n",
       " 'complete': 725,\n",
       " 'buy': 720,\n",
       " 'committee': 719,\n",
       " 'times': 716,\n",
       " 'longer': 716,\n",
       " 'companies': 713,\n",
       " 'store': 713,\n",
       " 'prospect': 712,\n",
       " 'lot': 710,\n",
       " 'option': 708,\n",
       " 'press': 706,\n",
       " 'production': 701,\n",
       " 'example': 701,\n",
       " 'agreement': 701,\n",
       " 'archives': 698,\n",
       " 'process': 698,\n",
       " 'type': 696,\n",
       " 'lcd': 696,\n",
       " 'joint': 695,\n",
       " 'simply': 694,\n",
       " 'bbldkbb': 693,\n",
       " 'charsetiso': 692,\n",
       " 'friday': 690,\n",
       " 'large': 688,\n",
       " 'seismic': 688,\n",
       " 'analog': 685,\n",
       " 'sun': 675,\n",
       " 'visit': 674,\n",
       " 'john': 672,\n",
       " 'tel': 670,\n",
       " 'rolex': 666,\n",
       " 'book': 665,\n",
       " 'shares': 664,\n",
       " 'ventures': 664,\n",
       " 'ago': 662,\n",
       " 'wrong': 660,\n",
       " 'click': 659,\n",
       " 'investment': 656,\n",
       " 'sensors': 655,\n",
       " 'private': 654,\n",
       " 'source': 653,\n",
       " 'field': 652,\n",
       " 'answer': 652,\n",
       " 'opportunity': 651,\n",
       " 'issue': 651,\n",
       " 'feel': 650,\n",
       " 'update': 646,\n",
       " 'allow': 642,\n",
       " 'usa': 641,\n",
       " 'split': 639,\n",
       " 'photoshop': 639,\n",
       " 'hc': 638,\n",
       " 'mar': 637,\n",
       " 'simple': 634,\n",
       " 'nov': 633,\n",
       " 'april': 632,\n",
       " 'shipping': 631,\n",
       " 'launch': 631,\n",
       " 'general': 629,\n",
       " 'solution': 628,\n",
       " 'building': 627,\n",
       " 'announces': 625,\n",
       " 'advance': 623,\n",
       " 'san': 623,\n",
       " 'mailing': 622,\n",
       " 'matter': 622,\n",
       " 'engineering': 622,\n",
       " 'drive': 621,\n",
       " 'gt': 621,\n",
       " 'main': 620,\n",
       " 'record': 617,\n",
       " 'trade': 617,\n",
       " 'effective': 615,\n",
       " 'link': 614,\n",
       " 'sincerely': 613,\n",
       " 'third': 613,\n",
       " 'monday': 613,\n",
       " 'shareholder': 612,\n",
       " 'thought': 610,\n",
       " 'fact': 609,\n",
       " 'word': 609,\n",
       " 'products': 609,\n",
       " 'characters': 608,\n",
       " 'smtp': 607,\n",
       " 'natural': 605,\n",
       " 'school': 604,\n",
       " 'connected': 604,\n",
       " 'canyon': 603,\n",
       " 'student': 603,\n",
       " 'men': 601,\n",
       " 'discussion': 599,\n",
       " 'worlds': 597,\n",
       " 'texas': 596,\n",
       " 'interest': 595,\n",
       " 'north': 592,\n",
       " 'ill': 592,\n",
       " 'lines': 591,\n",
       " 'mineral': 590,\n",
       " 'collection': 590,\n",
       " 'easy': 590,\n",
       " 'led': 589,\n",
       " 'hard': 588,\n",
       " 'extension': 588,\n",
       " 'directly': 587,\n",
       " 'true': 585,\n",
       " 'youll': 585,\n",
       " 'build': 584,\n",
       " 'edition': 582,\n",
       " 'connect': 582,\n",
       " 'history': 580,\n",
       " 'management': 580,\n",
       " 'details': 580,\n",
       " 'increase': 577,\n",
       " 'acrobat': 576,\n",
       " '\\\\t\\\\t': 576,\n",
       " 'jan': 576,\n",
       " 'signal': 575,\n",
       " 'function': 574,\n",
       " 'area': 574,\n",
       " 'swath': 574,\n",
       " 'dr': 574,\n",
       " 'httpwwwvimsedujeffarchivehtm': 574,\n",
       " 'numbers': 573,\n",
       " 'top': 573,\n",
       " 'left': 573,\n",
       " 'started': 570,\n",
       " 'reading': 569,\n",
       " 'device': 569,\n",
       " 'weeks': 568,\n",
       " 'size': 568,\n",
       " 'offers': 567,\n",
       " 'display': 567,\n",
       " 'mining': 564,\n",
       " 'conference': 563,\n",
       " 'processing': 561,\n",
       " 'degree': 560,\n",
       " 'dec': 560,\n",
       " 'character': 558,\n",
       " 'engaged': 557,\n",
       " 'deal': 557,\n",
       " 'independent': 556,\n",
       " 'interface': 555,\n",
       " 'box': 552,\n",
       " 'huge': 551,\n",
       " 'server': 550,\n",
       " 'machine': 550,\n",
       " 'choice': 548,\n",
       " 'dmdx': 548,\n",
       " 'developing': 547,\n",
       " 'normal': 545,\n",
       " 'fully': 544,\n",
       " 'mac': 543,\n",
       " 'chuo': 543,\n",
       " 'expect': 542,\n",
       " 'premiere': 542,\n",
       " 'te': 541,\n",
       " 'library': 540,\n",
       " 'lose': 539,\n",
       " 'speed': 539,\n",
       " 'didnt': 538,\n",
       " 'pretty': 538,\n",
       " 'resources': 537,\n",
       " 'play': 537,\n",
       " 'manager': 537,\n",
       " 'reply': 536,\n",
       " 'circuit': 536,\n",
       " 'customer': 535,\n",
       " 'sell': 535,\n",
       " 'president': 534,\n",
       " 'west': 534,\n",
       " 'close': 534,\n",
       " 'position': 534,\n",
       " 'making': 534,\n",
       " 'remember': 533,\n",
       " 'starshipdesign': 533,\n",
       " 'minerals': 532,\n",
       " 'nan': 532,\n",
       " 'watches': 527,\n",
       " 'move': 527,\n",
       " 'credit': 527,\n",
       " 'quality': 526,\n",
       " 'weight': 526,\n",
       " 'mu': 524,\n",
       " 'total': 523,\n",
       " 'int': 522,\n",
       " 'html': 522,\n",
       " 'paper': 521,\n",
       " 'open': 521,\n",
       " 'response': 520,\n",
       " 'language': 519,\n",
       " 'american': 519,\n",
       " 'located': 518,\n",
       " 'operations': 517,\n",
       " 'turned': 516,\n",
       " 'june': 516,\n",
       " 'la': 516,\n",
       " 'required': 515,\n",
       " 'cc': 515,\n",
       " 'havent': 513,\n",
       " 'legal': 511,\n",
       " 'return': 511,\n",
       " 'meeting': 511,\n",
       " 'producer': 510,\n",
       " 'sharp': 510,\n",
       " 'bad': 509,\n",
       " 'servos': 508,\n",
       " 'luck': 507,\n",
       " 'local': 506,\n",
       " 'cost': 505,\n",
       " 'communication': 503,\n",
       " 'correct': 503,\n",
       " 'gmt': 502,\n",
       " 'mike': 501,\n",
       " 'needed': 500,\n",
       " 'range': 499,\n",
       " 'called': 498,\n",
       " 'load': 498,\n",
       " 'loss': 497,\n",
       " 'held': 497,\n",
       " 'happy': 497,\n",
       " 'major': 496,\n",
       " 'america': 496,\n",
       " 'island': 494,\n",
       " 'water': 492,\n",
       " 'country': 491,\n",
       " 'result': 490,\n",
       " 'shareholders': 489,\n",
       " 'handyboardmediamitedu': 489,\n",
       " 'supply': 488,\n",
       " 'college': 487,\n",
       " 'applications': 487,\n",
       " 'early': 486,\n",
       " 'reference': 486,\n",
       " 'announced': 485,\n",
       " 'os': 485,\n",
       " 'network': 484,\n",
       " 'copy': 482,\n",
       " 'request': 481,\n",
       " 'focus': 481,\n",
       " 'issues': 481,\n",
       " 'mime': 479,\n",
       " 'advice': 476,\n",
       " 'cwtd': 476,\n",
       " 'expected': 475,\n",
       " 'risk': 475,\n",
       " 'consider': 475,\n",
       " 'directors': 475,\n",
       " 'cialis': 475,\n",
       " 'multiple': 473,\n",
       " 'center': 473,\n",
       " 'appreciated': 471,\n",
       " 'cash': 471,\n",
       " 'marketing': 471,\n",
       " 'venture': 471,\n",
       " 'parts': 471,\n",
       " 'returnpath': 470,\n",
       " 'driver': 470,\n",
       " 'ports': 469,\n",
       " 'dc': 467,\n",
       " 'highly': 466,\n",
       " 'interesting': 465,\n",
       " 'mm': 464,\n",
       " 'user': 463,\n",
       " 'south': 461,\n",
       " 'ability': 461,\n",
       " 'pay': 461,\n",
       " 'greko': 460,\n",
       " 'cpu': 459,\n",
       " 'level': 458,\n",
       " 'suggestions': 457,\n",
       " 'month': 456,\n",
       " 'director': 455,\n",
       " 'tenure': 455,\n",
       " 'knowledge': 454,\n",
       " 'industry': 454,\n",
       " 'verified': 454,\n",
       " 'wondering': 454,\n",
       " 'media': 454,\n",
       " 'soft': 454,\n",
       " 'lego': 454,\n",
       " 'growth': 452,\n",
       " 'bank': 452,\n",
       " 'sector': 451,\n",
       " 'stuff': 451,\n",
       " 'understand': 451,\n",
       " 'aa': 451,\n",
       " 'antonio': 450,\n",
       " 'members': 448,\n",
       " 'orgasms': 447,\n",
       " 'securities': 447,\n",
       " 'coming': 446,\n",
       " 'ascii': 445,\n",
       " 'drilling': 444,\n",
       " 'jonathan': 444,\n",
       " 'encore': 443,\n",
       " 'ross': 443,\n",
       " 'written': 442,\n",
       " 'books': 442,\n",
       " 'loan': 442,\n",
       " 'bestsellers': 441,\n",
       " 'names': 441,\n",
       " 'volume': 441,\n",
       " 'august': 441,\n",
       " 'phd': 441,\n",
       " 'programming': 440,\n",
       " 'boards': 440,\n",
       " 'unit': 440,\n",
       " 'screen': 439,\n",
       " 'dvd': 438,\n",
       " 'tuesday': 438,\n",
       " 'unicodeorg': 438,\n",
       " 'pins': 436,\n",
       " 'inreplyto': 436,\n",
       " 'darkwinguoregonedu': 436,\n",
       " 'interactive': 435,\n",
       " 'sat': 434,\n",
       " 'zl': 433,\n",
       " 'audition': 432,\n",
       " 'person': 431,\n",
       " 'friend': 431,\n",
       " 'card': 431,\n",
       " 'key': 429,\n",
       " 'series': 429,\n",
       " 'changes': 428,\n",
       " 'changed': 428,\n",
       " 'command': 427,\n",
       " 'hardware': 426,\n",
       " 'green': 426,\n",
       " 'clixme': 426,\n",
       " 'exciting': 424,\n",
       " 'ideas': 423,\n",
       " 'rate': 423,\n",
       " 'july': 423,\n",
       " 'unique': 422,\n",
       " 'delivery': 421,\n",
       " 'job': 421,\n",
       " 'team': 420,\n",
       " 'love': 420,\n",
       " 'papers': 418,\n",
       " 'talk': 417,\n",
       " 'martin': 417,\n",
       " 'pcode': 417,\n",
       " 'institute': 415,\n",
       " 'national': 415,\n",
       " 'term': 414,\n",
       " 'est': 414,\n",
       " 'isnt': 413,\n",
       " 'mhz': 413,\n",
       " 'man': 412,\n",
       " 'trace': 412,\n",
       " 'sex': 411,\n",
       " 'texada': 410,\n",
       " 'room': 409,\n",
       " 'difficult': 409,\n",
       " 'letter': 408,\n",
       " 'create': 407,\n",
       " 'item': 407,\n",
       " 'nevada': 407,\n",
       " 'val': 407,\n",
       " 'formula': 406,\n",
       " 'franklin': 405,\n",
       " 'manual': 403,\n",
       " 'allows': 403,\n",
       " 'xmailer': 403,\n",
       " 'unix': 401,\n",
       " 'global': 401,\n",
       " 'wont': 400,\n",
       " 'couple': 399,\n",
       " 'continue': 399,\n",
       " 'charge': 399,\n",
       " 'trading': 398,\n",
       " 'acres': 396,\n",
       " 'methods': 395,\n",
       " 'users': 393,\n",
       " 'single': 393,\n",
       " 'register': 392,\n",
       " 'search': 392,\n",
       " 'cable': 392,\n",
       " 'higher': 391,\n",
       " 'writes': 390,\n",
       " 'en': 390,\n",
       " 'graduate': 389,\n",
       " 'penis': 387,\n",
       " 'david': 387,\n",
       " 'exactly': 387,\n",
       " 'geological': 386,\n",
       " 'enjoy': 385,\n",
       " 'red': 384,\n",
       " 'included': 384,\n",
       " 'ready': 383,\n",
       " 'ii': 382,\n",
       " 'inform': 382,\n",
       " 'reason': 381,\n",
       " 'texthtml': 380,\n",
       " 'writing': 380,\n",
       " 'degrees': 380,\n",
       " 'interrog': 379,\n",
       " 'gapj': 378,\n",
       " 'health': 378,\n",
       " 'march': 377,\n",
       " 'bulk': 377,\n",
       " 'frank': 375,\n",
       " 'licensed': 372,\n",
       " 'happened': 371,\n",
       " 'enhancing': 371,\n",
       " 'comments': 371,\n",
       " 'remove': 371,\n",
       " 'nice': 370,\n",
       " 'minutes': 369,\n",
       " 'addresses': 368,\n",
       " 'tests': 368,\n",
       " 'initial': 367,\n",
       " 'values': 367,\n",
       " 'hot': 366,\n",
       " 'jun': 366,\n",
       " 'chips': 365,\n",
       " 'asked': 364,\n",
       " 'security': 364,\n",
       " 'confirm': 364,\n",
       " 'pounds': 364,\n",
       " 'sound': 364,\n",
       " 'max': 362,\n",
       " 'tomorrow': 361,\n",
       " 'techniques': 361,\n",
       " 'successful': 361,\n",
       " 'worked': 361,\n",
       " 'purchase': 361,\n",
       " 'outputs': 361,\n",
       " 'headquartered': 360,\n",
       " 'url': 360,\n",
       " 'rich': 359,\n",
       " 'house': 359,\n",
       " 'foreign': 358,\n",
       " 'ground': 358,\n",
       " 'routines': 358,\n",
       " 'worldwide': 357,\n",
       " 'designed': 357,\n",
       " 'winning': 357,\n",
       " 'species': 357,\n",
       " 'cr': 357,\n",
       " 'eye': 356,\n",
       " 'head': 356,\n",
       " 'funds': 355,\n",
       " 'inside': 355,\n",
       " 'personal': 354,\n",
       " 'feb': 354,\n",
       " 'switch': 353,\n",
       " 'climb': 353,\n",
       " 'connection': 352,\n",
       " 'lottery': 352,\n",
       " 'mobile': 351,\n",
       " 'advanced': 351,\n",
       " 'undertaken': 350,\n",
       " 'ma': 350,\n",
       " 'amount': 349,\n",
       " 'completed': 348,\n",
       " 'geophysical': 347,\n",
       " 'chance': 347,\n",
       " 'radio': 347,\n",
       " 'precedence': 347,\n",
       " 'specific': 345,\n",
       " 'multipart': 344,\n",
       " 'directory': 344,\n",
       " 'returns': 344,\n",
       " 'method': 344,\n",
       " 'exchange': 344,\n",
       " 'chinas': 343,\n",
       " 'oct': 343,\n",
       " 'generate': 342,\n",
       " 'engine': 342,\n",
       " 'material': 341,\n",
       " 'profile': 341,\n",
       " 'care': 341,\n",
       " 'resource': 340,\n",
       " 'extra': 340,\n",
       " 'built': 340,\n",
       " '\\\\tthe': 340,\n",
       " 'jp': 340,\n",
       " 'events': 339,\n",
       " 'ctxe': 338,\n",
       " 'moving': 338,\n",
       " 'registration': 338,\n",
       " 'reported': 337,\n",
       " 'model': 337,\n",
       " 'professor': 337,\n",
       " 'resistor': 337,\n",
       " 'confidentiality': 336,\n",
       " 'secure': 336,\n",
       " 'electronics': 336,\n",
       " 'youve': 335,\n",
       " 'phase': 335,\n",
       " 'developments': 334,\n",
       " 'visa': 334,\n",
       " 'helps': 334,\n",
       " 'avoid': 334,\n",
       " 'le': 334,\n",
       " 'las': 333,\n",
       " 'markets': 333,\n",
       " 'managed': 333,\n",
       " 'appreciate': 333,\n",
       " 'java': 333,\n",
       " 'technical': 332,\n",
       " 'aggressive': 332,\n",
       " 'realize': 332,\n",
       " 'terms': 332,\n",
       " 'linux': 332,\n",
       " 'break': 331,\n",
       " 'bytes': 331,\n",
       " 'ram': 331,\n",
       " 'largest': 330,\n",
       " 'todays': 330,\n",
       " 'assembly': 330,\n",
       " 'functions': 329,\n",
       " 'polaroid': 329,\n",
       " 'groups': 328,\n",
       " 'worldclass': 328,\n",
       " 'guess': 328,\n",
       " 'wide': 328,\n",
       " 'base': 328,\n",
       " 'respect': 328,\n",
       " 'study': 326,\n",
       " 'statement': 326,\n",
       " 'sperm': 326,\n",
       " 'article': 325,\n",
       " 'takes': 324,\n",
       " 'mit': 324,\n",
       " 'pulse': 324,\n",
       " 'vegas': 323,\n",
       " 'view': 323,\n",
       " 'draw': 323,\n",
       " 'category': 323,\n",
       " 'finally': 323,\n",
       " 'reset': 323,\n",
       " 'bilbo': 321,\n",
       " 'verde': 321,\n",
       " 'meaning': 321,\n",
       " 'setting': 320,\n",
       " 'operating': 320,\n",
       " 'respond': 320,\n",
       " 'fontfamily': 319,\n",
       " 'tabs': 318,\n",
       " 'portfolio': 317,\n",
       " 'claim': 317,\n",
       " 'wanted': 317,\n",
       " 'canadian': 317,\n",
       " 'stepper': 317,\n",
       " 'andor': 316,\n",
       " 'reserves': 316,\n",
       " 'robotics': 316,\n",
       " 'mind': 315,\n",
       " 'ps': 315,\n",
       " 'publiclistsapplecom': 315,\n",
       " 'pick': 314,\n",
       " 'black': 314,\n",
       " 'void': 314,\n",
       " 'distance': 314,\n",
       " 'batteries': 313,\n",
       " 'tremendous': 312,\n",
       " 'months': 312,\n",
       " 'dated': 312,\n",
       " 'community': 312,\n",
       " 'voice': 312,\n",
       " 'analysis': 312,\n",
       " 'fall': 311,\n",
       " 'advantage': 311,\n",
       " 'providence': 311,\n",
       " 'materials': 311,\n",
       " 'rat': 311,\n",
       " 'sort': 310,\n",
       " 'structure': 310,\n",
       " 'fontsize': 310,\n",
       " 'english': 309,\n",
       " 'opt': 309,\n",
       " 'win': 309,\n",
       " 'lost': 309,\n",
       " 'environment': 309,\n",
       " 'sexual': 309,\n",
       " 'follow': 308,\n",
       " 'fixed': 308,\n",
       " 'external': 308,\n",
       " 'ph': 307,\n",
       " 'hand': 307,\n",
       " 'heard': 307,\n",
       " 'bbb': 306,\n",
       " 'rest': 306,\n",
       " 'clear': 306,\n",
       " 'attention': 306,\n",
       " 'tv': 306,\n",
       " 'sciences': 306,\n",
       " 'stages': 305,\n",
       " 'mention': 305,\n",
       " 'step': 305,\n",
       " 'clock': 305,\n",
       " 'marine': 305,\n",
       " 'dynamic': 304,\n",
       " 'hightech': 304,\n",
       " 'customers': 304,\n",
       " 'formatflowed': 303,\n",
       " 'relief': 303,\n",
       " 'financial': 303,\n",
       " 'michael': 303,\n",
       " 'includes': 303,\n",
       " 'picture': 302,\n",
       " 'notice': 302,\n",
       " '\\\\tid': 302,\n",
       " 'worry': 302,\n",
       " 'cheap': 302,\n",
       " 'feminist': 302,\n",
       " 'protection': 300,\n",
       " 'biology': 300,\n",
       " 'arizona': 300,\n",
       " 'region': 299,\n",
       " 'wouldnt': 299,\n",
       " 'appear': 299,\n",
       " 'sales': 299,\n",
       " 'lower': 299,\n",
       " 'difference': 297,\n",
       " 'prize': 297,\n",
       " 'dept': 297,\n",
       " 'session': 297,\n",
       " 'figure': 297,\n",
       " 'staff': 297,\n",
       " 'routine': 297,\n",
       " 'downloaded': 297,\n",
       " 'estate': 296,\n",
       " 'final': 296,\n",
       " 'completion': 296,\n",
       " 'monthly': 296,\n",
       " 'direct': 296,\n",
       " 'inputs': 296,\n",
       " 'gpd': 296,\n",
       " 'wait': 295,\n",
       " 'social': 295,\n",
       " 'night': 295,\n",
       " 'wall': 294,\n",
       " 'electronic': 294,\n",
       " 'watsuncccolumbiaedu': 294,\n",
       " 'interrupt': 293,\n",
       " 'annual': 293,\n",
       " 'da': 293,\n",
       " 'provided': 292,\n",
       " 'wells': 292,\n",
       " 'public': 292,\n",
       " 'cut': 292,\n",
       " 'bill': 292,\n",
       " 'dollars': 291,\n",
       " 'references': 291,\n",
       " 'cheers': 291,\n",
       " 'success': 291,\n",
       " 'wire': 291,\n",
       " 'accelerate': 290,\n",
       " 'projects': 290,\n",
       " 'diet': 289,\n",
       " 'review': 289,\n",
       " 'car': 289,\n",
       " 'tools': 288,\n",
       " 'ways': 288,\n",
       " 'star': 288,\n",
       " 'earth': 287,\n",
       " 'cd': 287,\n",
       " 'learn': 287,\n",
       " 'street': 287,\n",
       " 'classes': 286,\n",
       " 'documentation': 286,\n",
       " 'food': 286,\n",
       " 'al': 286,\n",
       " 'va': 286,\n",
       " 'plasma': 286,\n",
       " 'estimated': 285,\n",
       " 'earning': 285,\n",
       " 'dos': 285,\n",
       " 'ribbon': 285,\n",
       " 'terminal': 284,\n",
       " 'australia': 284,\n",
       " 'header': 284,\n",
       " 'pack': 284,\n",
       " 'remote': 283,\n",
       " 'mother': 283,\n",
       " 'skills': 283,\n",
       " 'published': 283,\n",
       " 'white': 283,\n",
       " 'separator': 283,\n",
       " 'agent': 282,\n",
       " 'california': 281,\n",
       " 'inches': 281,\n",
       " 'air': 281,\n",
       " 'ceo': 281,\n",
       " 'lowest': 280,\n",
       " 'rework': 280,\n",
       " 'september': 280,\n",
       " 'require': 280,\n",
       " 'human': 280,\n",
       " 'components': 280,\n",
       " 'kit': 280,\n",
       " 'purpose': 279,\n",
       " 'emerging': 279,\n",
       " 'suite': 279,\n",
       " 'encoder': 279,\n",
       " 'trouble': 278,\n",
       " 'brought': 278,\n",
       " 'road': 278,\n",
       " 'considered': 277,\n",
       " 'meds': 277,\n",
       " 'target': 277,\n",
       " 'color': 277,\n",
       " 'errors': 277,\n",
       " 'pill': 276,\n",
       " 'direction': 276,\n",
       " 'zh': 276,\n",
       " 'appropriate': 275,\n",
       " 'basic': 275,\n",
       " 'pwm': 275,\n",
       " 'thursday': 274,\n",
       " 'talking': 274,\n",
       " 'thinking': 273,\n",
       " 'transfer': 273,\n",
       " '\\\\t\\\\t\\\\t': 273,\n",
       " 'leading': 273,\n",
       " 'masters': 273,\n",
       " 'instructions': 272,\n",
       " 'receiving': 272,\n",
       " 'decision': 271,\n",
       " 'attached': 271,\n",
       " 'placement': 271,\n",
       " 'earlier': 271,\n",
       " 'libraries': 270,\n",
       " 'fields': 270,\n",
       " 'late': 270,\n",
       " ...}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a dictionary to store word counts\n",
    "uniqueWordsCount = {}\n",
    "\n",
    "# Iterate through each row in the training DataFrame\n",
    "for idx, record in traindf.iterrows():\n",
    "    for word in str(record['Content']).split():  # Use 'Content' as the column name\n",
    "        if word in uniqueWordsCount:\n",
    "            uniqueWordsCount[word] += 1\n",
    "        else:\n",
    "            uniqueWordsCount[word] = 1\n",
    "\n",
    "# Sort the dictionary by value in descending order\n",
    "sortedUniqueWordsCount = sorted(uniqueWordsCount.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "# Extract the 10,000 most common words\n",
    "topCommonWords = dict(sortedUniqueWordsCount[:10000])\n",
    "\n",
    "# Display the most common words\n",
    "topCommonWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c3027e9b-89de-4cf4-9c7c-8eb79fa0f754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   will  bbbb  board  company  price  gold  adobe  email  list  time  ...  \\\n",
      "0     1     0      0        0      0     0      0      1     1     0  ...   \n",
      "1     0     0      0        0      0     0      0      0     1     0  ...   \n",
      "2     0     0      0        0      0     0      0      0     0     0  ...   \n",
      "3     0     0      0        0      0     0      0      0     1     0  ...   \n",
      "4     0     0      0        0      0     0      0      0     1     0  ...   \n",
      "\n",
      "   amm  khmm  tkhmm  cha  tgn  chzhw  chzhwr  lkg  pvce  wll  \n",
      "0    0     0      0    0    0      0       0    0     0    0  \n",
      "1    0     0      0    0    0      0       0    0     0    0  \n",
      "2    0     0      0    0    0      0       0    0     0    0  \n",
      "3    0     0      0    0    0      0       0    0     0    0  \n",
      "4    0     0      0    0    0      0       0    0     0    0  \n",
      "\n",
      "[5 rows x 10000 columns]\n",
      "   will  bbbb  board  company  price  gold  adobe  email  list  time  ...  \\\n",
      "0     0     0      0        0      0     1      0      0     0     0  ...   \n",
      "1     0     0      0        0      0     0      0      0     0     1  ...   \n",
      "2     0     0      0        0      0     0      0      0     0     0  ...   \n",
      "3     1     0      0        0      0     0      0      0     0     0  ...   \n",
      "4     1     0      0        0      1     0      0      0     0     0  ...   \n",
      "\n",
      "   amm  khmm  tkhmm  cha  tgn  chzhw  chzhwr  lkg  pvce  wll  \n",
      "0    0     0      0    0    0      0       0    0     0    0  \n",
      "1    0     0      0    0    0      0       0    0     0    0  \n",
      "2    0     0      0    0    0      0       0    0     0    0  \n",
      "3    0     0      0    0    0      0       0    0     0    0  \n",
      "4    0     0      0    0    0      0       0    0     0    0  \n",
      "\n",
      "[5 rows x 10000 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Combine content from ham and spam training sets\n",
    "all_messages = pd.concat([trainingHam['Content'], trainingSpam['Content']])\n",
    "\n",
    "# Count word occurrences\n",
    "all_words = all_messages.fillna('').str.cat(sep=' ').split()\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Get the 10,000 most common words\n",
    "vocabulary = [word for word, _ in word_counts.most_common(10000)]\n",
    "\n",
    "# Function to create feature matrices\n",
    "def create_feature_matrix(dataframe, vocabulary):\n",
    "    matrix = np.zeros((len(dataframe), len(vocabulary)), dtype=int)\n",
    "    \n",
    "    for i, message in enumerate(dataframe['Content'].fillna('')):  # Fill NaN with empty string\n",
    "        message_words = message.split()  # Split the message directly\n",
    "        for word in message_words:\n",
    "            if word in vocabulary:\n",
    "                matrix[i, vocabulary.index(word)] = 1  # Set 1 for word presence\n",
    "                \n",
    "    return matrix\n",
    "\n",
    "# Create feature matrices\n",
    "ham_feature_matrix = create_feature_matrix(trainingHam, vocabulary)\n",
    "spam_feature_matrix = create_feature_matrix(trainingSpam, vocabulary)\n",
    "\n",
    "# Optional: Convert feature matrices to DataFrames for easier viewing\n",
    "ham_matrix_df = pd.DataFrame(ham_feature_matrix, columns=vocabulary)\n",
    "spam_matrix_df = pd.DataFrame(spam_feature_matrix, columns=vocabulary)\n",
    "\n",
    "# Display the DataFrame (optional)\n",
    "print(ham_matrix_df.head())\n",
    "print(spam_matrix_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3cd4b28c-5188-493c-bdf1-cbd9278ad70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>will</th>\n",
       "      <th>bbbb</th>\n",
       "      <th>board</th>\n",
       "      <th>company</th>\n",
       "      <th>price</th>\n",
       "      <th>gold</th>\n",
       "      <th>adobe</th>\n",
       "      <th>email</th>\n",
       "      <th>list</th>\n",
       "      <th>time</th>\n",
       "      <th>...</th>\n",
       "      <th>amm</th>\n",
       "      <th>khmm</th>\n",
       "      <th>tkhmm</th>\n",
       "      <th>cha</th>\n",
       "      <th>tgn</th>\n",
       "      <th>chzhw</th>\n",
       "      <th>chzhwr</th>\n",
       "      <th>lkg</th>\n",
       "      <th>pvce</th>\n",
       "      <th>wll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   will  bbbb  board  company  price  gold  adobe  email  list  time  ...  \\\n",
       "0     1     0      0        0      0     0      0      1     1     0  ...   \n",
       "1     0     0      0        0      0     0      0      0     1     0  ...   \n",
       "2     0     0      0        0      0     0      0      0     0     0  ...   \n",
       "3     0     0      0        0      0     0      0      0     1     0  ...   \n",
       "4     0     0      0        0      0     0      0      0     1     0  ...   \n",
       "\n",
       "   amm  khmm  tkhmm  cha  tgn  chzhw  chzhwr  lkg  pvce  wll  \n",
       "0    0     0      0    0    0      0       0    0     0    0  \n",
       "1    0     0      0    0    0      0       0    0     0    0  \n",
       "2    0     0      0    0    0      0       0    0     0    0  \n",
       "3    0     0      0    0    0      0       0    0     0    0  \n",
       "4    0     0      0    0    0      0       0    0     0    0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8d54f61d-b7d7-4602-b320-4303d34f880e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>will</th>\n",
       "      <th>bbbb</th>\n",
       "      <th>board</th>\n",
       "      <th>company</th>\n",
       "      <th>price</th>\n",
       "      <th>gold</th>\n",
       "      <th>adobe</th>\n",
       "      <th>email</th>\n",
       "      <th>list</th>\n",
       "      <th>time</th>\n",
       "      <th>...</th>\n",
       "      <th>amm</th>\n",
       "      <th>khmm</th>\n",
       "      <th>tkhmm</th>\n",
       "      <th>cha</th>\n",
       "      <th>tgn</th>\n",
       "      <th>chzhw</th>\n",
       "      <th>chzhwr</th>\n",
       "      <th>lkg</th>\n",
       "      <th>pvce</th>\n",
       "      <th>wll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   will  bbbb  board  company  price  gold  adobe  email  list  time  ...  \\\n",
       "0     0     0      0        0      0     1      0      0     0     0  ...   \n",
       "1     0     0      0        0      0     0      0      0     0     1  ...   \n",
       "2     0     0      0        0      0     0      0      0     0     0  ...   \n",
       "3     1     0      0        0      0     0      0      0     0     0  ...   \n",
       "4     1     0      0        0      1     0      0      0     0     0  ...   \n",
       "\n",
       "   amm  khmm  tkhmm  cha  tgn  chzhw  chzhwr  lkg  pvce  wll  \n",
       "0    0     0      0    0    0      0       0    0     0    0  \n",
       "1    0     0      0    0    0      0       0    0     0    0  \n",
       "2    0     0      0    0    0      0       0    0     0    0  \n",
       "3    0     0      0    0    0      0       0    0     0    0  \n",
       "4    0     0      0    0    0      0       0    0     0    0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_matrix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a3da185b-6e66-4834-9341-60ee66e28f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior probability for ham (p(c = ham)): 0.3531924882629108\n",
      "Prior probability for spam (p(c = spam)): 0.6468075117370892\n"
     ]
    }
   ],
   "source": [
    "# Number of ham and spam emails in the training set\n",
    "n_ham = len(trainingHam)  # Ham: Label 0\n",
    "n_spam = len(trainingSpam)  # Spam: Label 1\n",
    "n_doc = len(traindf)  # Total number of emails in the training set\n",
    "\n",
    "# Compute priors\n",
    "p_ham = n_ham / n_doc\n",
    "p_spam = n_spam / n_doc\n",
    "\n",
    "# Display the priors\n",
    "print(\"Prior probability for ham (p(c = ham)):\", p_ham)\n",
    "print(\"Prior probability for spam (p(c = spam)):\", p_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ae4345e4-309c-4fe1-9843-1bcb6bea2eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood of each word given spam (with Laplace smoothing): [5.54212442e-03 2.16603229e-03 1.12452547e-03 ... 1.76100186e-05\n",
      " 1.76100186e-05 1.76100186e-05]\n",
      "Likelihood of each word given ham (with Laplace smoothing): [6.28798363e-03 8.20528530e-06 5.50574643e-03 ... 2.73509510e-06\n",
      " 2.73509510e-06 2.73509510e-06]\n"
     ]
    }
   ],
   "source": [
    "# Compute likelihoods for each word in spam and ham with Laplace smoothing\n",
    "\n",
    "def compute_likelihood(feature_matrix_spam, feature_matrix_ham, vocabulary):\n",
    "    # Initialize arrays for the likelihoods of each word given spam or ham\n",
    "    likelihood_spam_words = np.zeros(len(vocabulary))\n",
    "    likelihood_ham_words = np.zeros(len(vocabulary))\n",
    "    \n",
    "    # Count occurrences of each word in spam and ham emails\n",
    "    word_counts_spam = np.sum(feature_matrix_spam, axis=0)\n",
    "    word_counts_ham = np.sum(feature_matrix_ham, axis=0)\n",
    "    \n",
    "    # Calculate total words in spam and ham sets\n",
    "    total_words_spam = np.sum(word_counts_spam)\n",
    "    total_words_ham = np.sum(word_counts_ham)\n",
    "    \n",
    "    # Laplace smoothing parameter and the number of possible classes (spam and ham)\n",
    "    smoothing_factor = 1\n",
    "    num_classes = 2\n",
    "\n",
    "    # Calculate likelihood for each word in vocabulary using Laplace smoothing\n",
    "    for i in range(len(vocabulary)):\n",
    "        likelihood_spam_words[i] = (word_counts_spam[i] + smoothing_factor) / (total_words_spam + smoothing_factor * num_classes)\n",
    "        likelihood_ham_words[i] = (word_counts_ham[i] + smoothing_factor) / (total_words_ham + smoothing_factor * num_classes)\n",
    "    \n",
    "    return likelihood_spam_words, likelihood_ham_words\n",
    "\n",
    "# Calculate likelihoods for spam and ham words\n",
    "likelihood_spam, likelihood_ham = compute_likelihood(spam_feature_matrix, ham_feature_matrix, vocabulary)\n",
    "\n",
    "# Display results\n",
    "print(\"Likelihood of each word given spam (with Laplace smoothing):\", likelihood_spam)\n",
    "print(\"Likelihood of each word given ham (with Laplace smoothing):\", likelihood_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0e8c4b2e-4ad3-447d-a99e-d13476a6f6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Content  Label  Prediction\n",
      "0  mailing list queried weeks ago running set arc...      0           0\n",
      "1   luxury watches buy rolex rolex cartier bvlgar...      1           1\n",
      "2  academic qualifications prestigious nonacc red...      1           1\n",
      "3  greetings verify subscription planfans list ch...      0           0\n",
      "4  chauncey conferred luscious continued tonsilli...      1           0\n"
     ]
    }
   ],
   "source": [
    "# Classify emails using computed log probabilities for ham and spam\n",
    "def classify_email(email_content, ham_likelihoods, spam_likelihoods, prior_ham, prior_spam):\n",
    "    # Initialize log probabilities with prior probabilities for ham and spam\n",
    "    log_prob_ham = np.log(prior_ham)\n",
    "    log_prob_spam = np.log(prior_spam)\n",
    "    \n",
    "    # Ensure email content is treated as a string to handle non-string entries\n",
    "    words_in_email = str(email_content).split()\n",
    "    \n",
    "    # Compute log probabilities based on word likelihoods\n",
    "    for word in words_in_email:\n",
    "        if word in vocabulary:  # Check if word is in the most common vocabulary list\n",
    "            word_index = vocabulary.index(word)\n",
    "            log_prob_ham += np.log(ham_likelihoods[word_index])\n",
    "            log_prob_spam += np.log(spam_likelihoods[word_index])\n",
    "    \n",
    "    # Compare the final log probabilities and classify as ham (0) or spam (1)\n",
    "    return 0 if log_prob_ham > log_prob_spam else 1\n",
    "\n",
    "# Using .loc[] to avoid SettingWithCopyWarning\n",
    "traindf.loc[:, 'Prediction'] = traindf['Content'].apply(lambda email: classify_email(email, likelihood_ham, likelihood_spam, p_ham, p_spam))\n",
    "\n",
    "# Display some of the classification results\n",
    "print(traindf[['Content', 'Label', 'Prediction']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cae1890a-dd43-4feb-b5a0-5b6fa312e6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 21300 emails, the number of correctly classified emails is 20510.\n",
      "The percentage of correctly classified emails is 96.29%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of correctly classified emails\n",
    "correct_predictions = (traindf['Label'] == traindf['Prediction']).sum()\n",
    "total_emails = len(traindf)\n",
    "accuracy_percentage = (correct_predictions / total_emails) * 100\n",
    "\n",
    "# Display results\n",
    "print(f\"Out of {total_emails} emails, the number of correctly classified emails is {correct_predictions}.\")\n",
    "print(f\"The percentage of correctly classified emails is {accuracy_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d579f-74c7-4df5-a948-0501348b8a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure there are no NaN values in 'Content' to avoid errors in `split()`\n",
    "testdf.loc[:, 'Content'] = testdf['Content'].fillna(\"\")\n",
    "\n",
    "# Apply the classification function using the correct function name\n",
    "testdf['predi'] = testdf['Content'].apply(lambda email: classify_email(email, likelihood_ham, likelihood_spam, p_ham, p_spam))\n",
    "\n",
    "# Optional: Print the head of testdf to confirm the 'predi' column was created\n",
    "print(testdf[['Content', 'predi']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0376db-930c-485d-89ad-01dcdecd6ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate = 0\n",
    "for index, row in test_df.iterrows():\n",
    "    if float(row['classification']) == float(row['predi']):\n",
    "        calculate += 1\n",
    "print(f\"Out of {len(test_df)} emails, the number of emails that are classified correctly is {calculate}. The percentage of correctly classified emails is {calculate/len(test_df)*100}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8da9d9-8dc7-4fb2-8f03-6da2a07cdb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'classification' and 'predi' are the correct column names in testdf\n",
    "actual = np.array(testdf['Label'])  # True labels\n",
    "predicted = np.array(testdf['predi'])  # Predicted labels\n",
    "\n",
    "# Create confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(actual, predicted, labels=[0, 1])\n",
    "\n",
    "# Visualize the confusion matrix using a heatmap\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print rates\n",
    "print(\"False Positive Rate (FP) -\", confusion_matrix[0][1]) \n",
    "print(\"False Negative Rate (FN) -\", confusion_matrix[1][0]) \n",
    "print(\"True Positive Rate (TP) -\", confusion_matrix[1][1]) \n",
    "print(\"True Negative Rate (TN) -\", confusion_matrix[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c2c7e-a136-47fc-a36a-52796e2081c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
